[ ![logo](../../../assets/logo.svg) ](../../ "OpenAI Agents SDK") OpenAI Agents SDK 

[ openai-agents-python  ](https://github.com/openai/openai-agents-python "ãƒªãƒã‚¸ãƒˆãƒªã¸")

  * [ ã¯ã˜ã‚ã«  ](../../)
  * [ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ  ](../../quickstart/)
  * [ ã‚³ãƒ¼ãƒ‰ä¾‹  ](../../examples/)
  * ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ  ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ 
    * [ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ  ](../../agents/)
    * [ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè¡Œ  ](../../running_agents/)
    * [ çµæœ  ](../../results/)
    * [ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°  ](../../streaming/)
    * [ ãƒ„ãƒ¼ãƒ«  ](../../tools/)
    * [ Model context protocol (MCP)  ](../../mcp/)
    * [ ãƒãƒ³ãƒ‰ã‚ªãƒ•  ](../../handoffs/)
    * [ ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°  ](../../tracing/)
    * [ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†  ](../../context/)
    * [ ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«  ](../../guardrails/)
    * [ è¤‡æ•°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³  ](../../multi_agent/)
    * ãƒ¢ãƒ‡ãƒ«  ãƒ¢ãƒ‡ãƒ« 
      * [ ãƒ¢ãƒ‡ãƒ«  ](../../models/)
      * [ LiteLLM çµŒç”±ã§ã®ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨  ](../../models/litellm/)
    * [ SDK ã®è¨­å®š  ](../../config/)
    * [ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¯è¦–åŒ–  ](../../visualization/)
    * éŸ³å£°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ  éŸ³å£°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ 
      * ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ  [ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ  ](./) ç›®æ¬¡ 
        * å‰ææ¡ä»¶ 
        * ã‚³ãƒ³ã‚»ãƒ—ãƒˆ 
        * ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ 
        * éŸ³å£°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ 
        * ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œ 
        * ã¾ã¨ã‚ã¦å®Ÿè¡Œ 
      * [ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼  ](../pipeline/)
      * [ ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°  ](../tracing/)



ç›®æ¬¡ 

  * å‰ææ¡ä»¶ 
  * ã‚³ãƒ³ã‚»ãƒ—ãƒˆ 
  * ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ 
  * éŸ³å£°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ 
  * ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œ 
  * ã¾ã¨ã‚ã¦å®Ÿè¡Œ 



# ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

## å‰ææ¡ä»¶

ã¾ãšã¯ [ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆæ‰‹é †](../../quickstart/) ã«å¾“ã£ã¦ Agents SDK ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã€ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚ãã®å¾Œã€SDK ã®éŸ³å£°é–¢é€£ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™:
    
    
    pip install 'openai-agents[voice]'
    

## ã‚³ãƒ³ã‚»ãƒ—ãƒˆ

æŠ¼ã•ãˆã¦ãŠãã¹ãä¸»ãªæ¦‚å¿µã¯ [`VoicePipeline`](../../../ref/voice/pipeline/#agents.voice.pipeline.VoicePipeline "VoicePipeline") ã§ã™ã€‚ã“ã‚Œã¯æ¬¡ã® 3 ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰æˆã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã§ã™ã€‚

  1. speech-to-text ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œã—ã¦éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã—ã¾ã™ã€‚ 
  2. é€šå¸¸ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçš„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§ã‚ã‚‹ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã€çµæœã‚’ç”Ÿæˆã—ã¾ã™ã€‚ 
  3. text-to-speech ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œã—ã¦çµæœã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å†ã³éŸ³å£°ã«å¤‰æ›ã—ã¾ã™ã€‚


    
    
    graph LR
        %% Input
        A["ğŸ¤ Audio Input"]
    
        %% Voice Pipeline
        subgraph Voice_Pipeline [Voice Pipeline]
            direction TB
            B["Transcribe (speech-to-text)"]
            C["Your Code"]:::highlight
            D["Text-to-speech"]
            B --> C --> D
        end
    
        %% Output
        E["ğŸ§ Audio Output"]
    
        %% Flow
        A --> Voice_Pipeline
        Voice_Pipeline --> E
    
        %% Custom styling
        classDef highlight fill:#ffcc66,stroke:#333,stroke-width:1px,font-weight:700;
    

## ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

ã¾ãšã€ã„ãã¤ã‹ã® ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¾ã—ã‚‡ã†ã€‚ã“ã® SDK ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã—ãŸã“ã¨ãŒã‚ã‚Œã°ã€è¦‹è¦šãˆãŒã‚ã‚‹ã¯ãšã§ã™ã€‚ã“ã“ã§ã¯è¤‡æ•°ã® ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ãƒãƒ³ãƒ‰ã‚ªãƒ•ã€ãã—ã¦ãƒ„ãƒ¼ãƒ«ã‚’ç”¨æ„ã—ã¾ã™ã€‚
    
    
    import asyncio
    import random
    
    from agents import (
        Agent,
        function_tool,
    )
    from agents.extensions.handoff_prompt import prompt_with_handoff_instructions
    
    
    
    @function_tool
    def get_weather(city: str) -> str:
        """Get the weather for a given city."""
        print(f"[debug] get_weather called with city: {city}")
        choices = ["sunny", "cloudy", "rainy", "snowy"]
        return f"The weather in {city} is {random.choice(choices)}."
    
    
    spanish_agent = Agent(
        name="Spanish",
        handoff_description="A spanish speaking agent.",
        instructions=prompt_with_handoff_instructions(
            "You're speaking to a human, so be polite and concise. Speak in Spanish.",
        ),
        model="gpt-4o-mini",
    )
    
    agent = Agent(
        name="Assistant",
        instructions=prompt_with_handoff_instructions(
            "You're speaking to a human, so be polite and concise. If the user speaks in Spanish, handoff to the spanish agent.",
        ),
        model="gpt-4o-mini",
        handoffs=[spanish_agent],
        tools=[get_weather],
    )
    

## éŸ³å£°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

[`SingleAgentVoiceWorkflow`](../../../ref/voice/workflow/#agents.voice.workflow.SingleAgentVoiceWorkflow "SingleAgentVoiceWorkflow") ã‚’ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¨ã—ã¦ã€ã‚·ãƒ³ãƒ—ãƒ«ãªéŸ³å£°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚
    
    
    from agents.voice import SingleAgentVoiceWorkflow, VoicePipeline
    pipeline = VoicePipeline(workflow=SingleAgentVoiceWorkflow(agent))
    

## ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œ
    
    
    import numpy as np
    import sounddevice as sd
    from agents.voice import AudioInput
    
    # For simplicity, we'll just create 3 seconds of silence
    # In reality, you'd get microphone data
    buffer = np.zeros(24000 * 3, dtype=np.int16)
    audio_input = AudioInput(buffer=buffer)
    
    result = await pipeline.run(audio_input)
    
    # Create an audio player using `sounddevice`
    player = sd.OutputStream(samplerate=24000, channels=1, dtype=np.int16)
    player.start()
    
    # Play the audio stream as it comes in
    async for event in result.stream():
        if event.type == "voice_stream_event_audio":
            player.write(event.data)
    

## ã¾ã¨ã‚ã¦å®Ÿè¡Œ
    
    
    import asyncio
    import random
    
    import numpy as np
    import sounddevice as sd
    
    from agents import (
        Agent,
        function_tool,
        set_tracing_disabled,
    )
    from agents.voice import (
        AudioInput,
        SingleAgentVoiceWorkflow,
        VoicePipeline,
    )
    from agents.extensions.handoff_prompt import prompt_with_handoff_instructions
    
    
    @function_tool
    def get_weather(city: str) -> str:
        """Get the weather for a given city."""
        print(f"[debug] get_weather called with city: {city}")
        choices = ["sunny", "cloudy", "rainy", "snowy"]
        return f"The weather in {city} is {random.choice(choices)}."
    
    
    spanish_agent = Agent(
        name="Spanish",
        handoff_description="A spanish speaking agent.",
        instructions=prompt_with_handoff_instructions(
            "You're speaking to a human, so be polite and concise. Speak in Spanish.",
        ),
        model="gpt-4o-mini",
    )
    
    agent = Agent(
        name="Assistant",
        instructions=prompt_with_handoff_instructions(
            "You're speaking to a human, so be polite and concise. If the user speaks in Spanish, handoff to the spanish agent.",
        ),
        model="gpt-4o-mini",
        handoffs=[spanish_agent],
        tools=[get_weather],
    )
    
    
    async def main():
        pipeline = VoicePipeline(workflow=SingleAgentVoiceWorkflow(agent))
        buffer = np.zeros(24000 * 3, dtype=np.int16)
        audio_input = AudioInput(buffer=buffer)
    
        result = await pipeline.run(audio_input)
    
        # Create an audio player using `sounddevice`
        player = sd.OutputStream(samplerate=24000, channels=1, dtype=np.int16)
        player.start()
    
        # Play the audio stream as it comes in
        async for event in result.stream():
            if event.type == "voice_stream_event_audio":
                player.write(event.data)
    
    
    if __name__ == "__main__":
        asyncio.run(main())
    

ã“ã®ä¾‹ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚ãªãŸã«è©±ã—ã‹ã‘ã¾ã™ã€‚å®Ÿéš›ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ä¼šè©±ã§ãã‚‹ãƒ‡ãƒ¢ã¯ã€[examples/voice/static](https://github.com/openai/openai-agents-python/tree/main/examples/voice/static) ã‚’ã”è¦§ãã ã•ã„ã€‚
